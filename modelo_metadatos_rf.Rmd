---
title: 'Ruta del Cacao'
subtitle: "Modelización: Metadatos con random forest"
params: 
  quiebre: 1 
output: 
    html_document: 
      code_download: true 
      number_sections: yes
      code_folding: hide
      theme: lumen
      toc: yes
      toc_float:
        collapsed: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(dplyr)
library(janitor)
library(readxl)
library(readr)
library(gt)
library(stringr)
library(text2vec)
library(LDAvis)
library(tidyr)
library(ggplot2)
library(lubridate)
library(stringr)
library(tidymodels)
library(tidytext)
library(stopwords)
library(textrecipes)
library(discrim)
library(vip)
library(themis)
library(tictoc)
library(ranger)
library(forcats)


library(doParallel)
all_cores <- parallel::detectCores(logical = FALSE)
registerDoParallel(cores = all_cores - 2)

set.seed(4321)


```
# Introducción

Realizamos un modelo con los metadatos de Ruta del Cacao y 
utilizando *random forests* y la variable *area*.  Características del modelo:

 - Documentos por debajo del umbral especificado en `quiebre` no se consideran 
 en la clasificación. 

- El número máximo de variables tfidf a considerar es de 30.

- No se calibran parámetros y el número de arboles considerados es 500


# Ingestión de los datos
```{r lectura}
crudos <- read_excel("datos/RDC_2019_V1.xlsx") %>% 
  clean_names() 

datos <- crudos  %>% 
  select(code,
         modo,
         name, 
         datecreated, 
         datemodified,
         author,
         org_interesada_remitente,
         org_interesada_destinatario,
         nombre_fichero,
         mimetype,
         size,
         path,
         area,
         nombre_tipo_documental,
         nombre_padre,
         nombre_abuelo,
         en_expte,
         nombre_serie_documental) %>% 
  unite(org_interesada,org_interesada_remitente:org_interesada_destinatario,
        remove = TRUE,
        na.rm = TRUE) %>% 
  mutate(
    date_created = ymd_hms(datecreated,tz = "UTC") - hours(5),
    date_modified = ymd_hms(datemodified,tz = "UTC") - hours(5)
    ) %>% 
   mutate(
    mes_creacion = month(datecreated,label = FALSE,abbr = FALSE),
    dia_semana_creacion = wday(datecreated,label = FALSE, 
                               week_start = 1,abbr = FALSE),
    dia_creacion = day(datecreated),
    hora_creacion = hour(datecreated),
    mes_modificacion = month(datemodified,label = FALSE,abbr = FALSE),
    dia_semana_modificacion = wday(datemodified,label = FALSE,
                                   week_start = 1,abbr = FALSE),
    dia_modificacion = day(datemodified),
    hora_modificacion = hour(datemodified)) %>% 
  rename(mime_type = mimetype) %>% 
  na.omit()
  

```

# Limpieza

Veamos la distribución de tipos de áreas:
```{r mostrar tipos de areas}
tabla <- datos %>% 
  group_by(area) %>% 
  summarize(frecuencia = n()) %>%
  arrange(desc(frecuencia)) %>% 
  mutate(
    total = sum(frecuencia),
    porcentaje = (frecuencia/total)*100,
    acumulado = cumsum(porcentaje),
    posicion = 1:n()
    ) %>%  
  select(-total) %>% 
  ungroup() 
  
tabla

```

Sacamos los nombres de las categorías que tienen menos del `r params$quiebre`% de 
representación en los datos:

```{r}
otros <- tabla %>% 
  filter(porcentaje < params$quiebre) %>% 
  pull(area)

```

Reclasificamos bajo "otros" esas categorías 
```{r}

datos <- datos %>%
  mutate(
    tipo = factor(if_else(
      area %in% otros,"otros",area))
  )

```

Verificamos la nueva distribución porcentual de las categorías:

```{r}
datos %>% 
  group_by(tipo) %>% 
  tally() %>% 
   arrange(desc(n)) %>% 
  mutate(
    total = sum(n),
    porcentaje = (n/total)*100,
    acumulado = cumsum(porcentaje),
    posicion = 1:n()
    ) %>%  
  select(-total) %>% 
  ungroup() %>% 
  gt()

```

En este punto, una opción sería continuar el proceso con esta nueva categoría
de **otros**. Lo que sugiere nuestra exploración es que mejor es omitirlos del todo en los siguientes pasos y es lo que hacemos a continuación


```{r}
datos <- datos %>% 
  filter(tipo != "otros") %>% 
  mutate(tipo = fct_drop(tipo))  # Importante: eliminar este nivel del factor

```

Y de nuevo, verificamos la distribución de los tipos:

```{r}
datos %>%   
  group_by(tipo) %>% 
  tally() %>% 
   arrange(desc(n)) %>% 
  mutate(
    total = sum(n),
    porcentaje = (n/total)*100,
    acumulado = cumsum(porcentaje),
    posicion = 1:n()
    ) %>%  
  select(-total) %>% 
  ungroup() %>% 
  gt()

```


Calcula de cuantas clases estamos hablando
```{r numero de clases}
n_clases <- datos %>% 
  distinct(tipo) %>% 
  tally() %>%
  pull()
```

# Construcción del modelo

## Paso 1: División
```{r division}
division <- initial_split(datos, strata = tipo)
entrenamiento <- training(division)
prueba <- testing(division)
pliegos <- vfold_cv(entrenamiento,v = 10,strata = tipo)
```

## Paso 2: Especificación del modelo

Esta es la de random forest, la activa por el momento.
Estos modelos tienen 3 paramétros principales:

- El número de arboles a construir
- El número de predictores que se muestrean en cada división del algoritmo (`mtry`)
- El número mínimo de observaciones necesarias para continuar la división del árbol (`min_n`)

```{r random forest}
rf_spec <- rand_forest() %>%
  set_args(trees = 500) %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("classification")
```



## Paso 3: Establecer la receta
```{r receta}
receta <- recipe(tipo ~
                   org_interesada +
                   mime_type + 
                   size + 
                   name + 
                   nombre_fichero + 
                   mes_creacion +
                   dia_semana_creacion +
                   dia_creacion +
                   hora_creacion +
                   mes_modificacion +
                   dia_semana_modificacion +
                   dia_modificacion +
                   hora_modificacion,
                   data = entrenamiento)

```



Receta sin "one hot encoding". No es necesaria para modelos de árbol

```{r receta no}
receta_no <- receta %>% 
  step_upsample(tipo, over_ratio = 1) %>% 
  step_normalize(size) %>% 
  step_other(org_interesada,
             mime_type,
             threshold = 0.01,
             other = "otro") %>% 
  step_tokenize(c(name,nombre_fichero)) %>% 
  step_stopwords(c(name, nombre_fichero),language = "es") %>% 
  step_tokenfilter(c(name,nombre_fichero),max_tokens = 30) %>% 
  step_tfidf(c(name,nombre_fichero))


```

Verifica que el upsampling funciona
```{r verifica up sampling}

  prep(receta_no) %>% 
    bake(new_data = NULL) %>% 
    ggplot(aes(tipo)) +
    geom_bar()

```


## Paso 4: Definir el flujo

### Con random forest
```{r flujo, eval = TRUE}
flujo <- workflow() %>% 
  add_model(rf_spec) %>% 
  add_recipe(receta_no)
```



## Paso 5: Ajustar el modelo

Este es el paso más intensivo computacionalmente
```{r, eval = TRUE, message=FALSE}
tic()
modelo_rs <- fit_resamples(
  flujo,
  pliegos,
  control = control_resamples(save_pred = TRUE, verbose = TRUE)
)
toc()

```


## Paso 6: Evaluar el modelo

```{r evaluar entrenamiento, eval = TRUE}
metricas <- collect_metrics(modelo_rs)
predicciones <- collect_predictions(modelo_rs)
metricas

```


### Graficar curvas ROC

```{r curvas roc}
predicciones %>%
  group_by(id) %>%
  roc_curve(truth = tipo, .pred_200:.pred_600,na_rm = TRUE) %>%
  autoplot() +
  labs(
    color = NULL,
    title = "ROC para meta_ubicación",
    subtitle = "Cada pliego un color diferente"
  )
```


### Comparación con el modelo nulo

Las métricas obtenidas deben ser superiores a las del modelo nulo para que tenga
sentido la modelización
```{r}
null_classification <- null_model() %>%
  set_engine("parsnip") %>%
  set_mode("classification")

null_rs <- workflow() %>%
  add_recipe(receta) %>%
  add_model(null_classification) %>%
  fit_resamples(
    pliegos
  )

null_rs %>%
  collect_metrics()
```

### Comparación con el conjunto de prueba

El modelo ajustado se mide con los datos de prueba:
```{r evaluacion prueba}
final_rf <- flujo %>% 
  last_fit(split = division)

```


y se obtienen las metricas y predicciones respectivas:
```{r metricas prueba}
final_res_metrics <- collect_metrics(final_rf)
final_res_predictions <- collect_predictions(final_rf)
correlacion_matthews <- mcc(final_res_predictions,truth = tipo, estimate = .pred_class)
final_res_metrics <- bind_rows(final_res_metrics, correlacion_matthews) %>% 
  select(-.config)

final_res_metrics


```

### Importancia de variables


```{r importancia de variables}
final_rf %>% 
  pluck(".workflow", 1) %>%   
  pull_workflow_fit() %>% 
  vip(geom = "point", num_features = 15)
```

### Matriz de confusión final

```{r}
final_res_predictions %>%
  conf_mat(truth = tipo, estimate = .pred_class) %>%
  autoplot(type = "heatmap")
```

### Curva ROC para el conjunto de prueba:


```{r curva ROC para conjunto de prueba}
final_res_predictions %>%
  roc_curve(truth = tipo, .pred_200:.pred_600,na_rm = TRUE) %>%
  autoplot()
```

## Paso 7: Guardar el modelo para pasos futuros

Potencialmente, se guarda el modelo como un objeto binario para ser usado por los 
meta clasificadores de la arquitectura
```{r, eval = TRUE}
mejor <- flujo %>% 
  fit(data = entrenamiento)

saveRDS(mejor, file = "modelo_metadata.rds")
write_csv(final_res_metrics,"ficha_metadatos.csv")

```


