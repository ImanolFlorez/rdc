---
title: 'Ruta del Cacao'
subtitle: "Modelización: Metadatos con random forest"
params: 
  quiebre: 1 
output: 
    html_document: 
      code_download: true 
      number_sections: yes
      code_folding: hide
      theme: lumen
      toc: yes
      toc_float:
        collapsed: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(dplyr)
library(janitor)
library(readxl)
library(readr)
library(gt)
library(stringr)
library(text2vec)
library(LDAvis)
library(tidyr)
library(ggplot2)
library(lubridate)
library(stringr)
library(tidymodels)
library(tidytext)
library(stopwords)
library(textrecipes)
library(discrim)
library(vip)
library(themis)
library(tictoc)
library(ranger)
library(forcats)


library(doParallel)
all_cores <- parallel::detectCores(logical = FALSE)
registerDoParallel(cores = all_cores - 2)

set.seed(4321)


```
# Introducción

Realizamos un modelo con los metadatos de Ruta del Cacaco y 
utilizando *random forests* y la variable *area*. 


# Ingestión de los datos
```{r lectura}
crudos <- read_excel("datos/RDC_2019_V1.xlsx") %>% 
  clean_names() 

datos <- crudos  %>% 
  select(code,
         modo,
         name, 
         datecreated, 
         datemodified,
         author,
         org_interesada_remitente,
         org_interesada_destinatario,
         nombre_fichero,
         mimetype,
         size,
         path,
         area,
         nombre_tipo_documental,
         nombre_padre,
         nombre_abuelo,
         en_expte,
         nombre_serie_documental) %>% 
  unite(org_interesada,org_interesada_remitente:org_interesada_destinatario,
        remove = TRUE,
        na.rm = TRUE) %>% 
  mutate(
    date_created = ymd_hms(datecreated,tz = "UTC") - hours(5),
    date_modified = ymd_hms(datemodified,tz = "UTC") - hours(5)
    ) %>% 
   mutate(
    mes_creacion = month(datecreated,label = FALSE,abbr = FALSE),
    dia_semana_creacion = wday(datecreated,label = FALSE, 
                               week_start = 1,abbr = FALSE),
    dia_creacion = day(datecreated),
    hora_creacion = hour(datecreated),
    mes_modificacion = month(datemodified,label = FALSE,abbr = FALSE),
    dia_semana_modificacion = wday(datemodified,label = FALSE,
                                   week_start = 1,abbr = FALSE),
    dia_modificacion = day(datemodified),
    hora_modificacion = hour(datemodified)) %>% 
  rename(mime_type = mimetype) %>% 
  na.omit()
  

```

# Limpieza

Veamos la distribución de tipos de áreas:
```{r mostrar tipos de areas}
tabla <- datos %>% 
  group_by(area) %>% 
  summarize(frecuencia = n()) %>%
  arrange(desc(frecuencia)) %>% 
  mutate(
    total = sum(frecuencia),
    porcentaje = (frecuencia/total)*100,
    acumulado = cumsum(porcentaje),
    posicion = 1:n()
    ) %>%  
  select(-total) %>% 
  ungroup() 
  
tabla

```

Sacamos los nombres de las categorías que tienen menos del `r params$quiebre`% de 
representación en los datos:

```{r}
otros <- tabla %>% 
  filter(porcentaje < params$quiebre) %>% 
  pull(area)

```

Reclasificamos bajo "otros" esas categorías 
```{r}

datos <- datos %>%
  mutate(
    tipo = factor(if_else(
      area %in% otros,"otros",area))
  )

```

Verificamos la nueva distribución porcentual de las categorías:

```{r}
datos %>% 
  group_by(tipo) %>% 
  tally() %>% 
   arrange(desc(n)) %>% 
  mutate(
    total = sum(n),
    porcentaje = (n/total)*100,
    acumulado = cumsum(porcentaje),
    posicion = 1:n()
    ) %>%  
  select(-total) %>% 
  ungroup() %>% 
  gt()

```

En este punto, una opción sería continuar el proceso con esta nueva categoría
de **otros**. Lo que sugiere nuestra exploración es que mejor es omitirlos del todo en los siguientes pasos y es lo que hacemos a continuación


```{r}
datos <- datos %>% 
  filter(tipo != "otros") %>% 
  mutate(tipo = fct_drop(tipo))  # Importante: eliminar este nivel del factor

```

Y de nuevo, verificamos la distribución de los tipos:

```{r}
datos %>%   
  group_by(tipo) %>% 
  tally() %>% 
   arrange(desc(n)) %>% 
  mutate(
    total = sum(n),
    porcentaje = (n/total)*100,
    acumulado = cumsum(porcentaje),
    posicion = 1:n()
    ) %>%  
  select(-total) %>% 
  ungroup() %>% 
  gt()

```


Calcula de cuantas clases estamos hablando
```{r numero de clases}
n_clases <- datos %>% 
  distinct(tipo) %>% 
  tally() %>%
  pull()
```

# Construcción del modelo

## Paso 1: División
```{r division}
division <- initial_split(datos, strata = tipo)
entrenamiento <- training(division)
prueba <- testing(division)
pliegos <- vfold_cv(entrenamiento,v = 10,strata = tipo)
```

## Paso 2: Especificación del modelo

Esta es la de random forest, la activa por el momento.
Estos modelos tienen 3 paramétros principales:

- El número de arboles a construir
- El número de predictores que se muestrean en cada división del algoritmo (`mtry`)
- El número mínimo de observaciones necesarias para continuar la división del árbol (`min_n`)

```{r random forest}
rf_spec <- rand_forest(
  mtry = tune(),
  trees = 500,
  min_n = tune()
) %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("classification")
```



## Paso 3: Establecer la receta
```{r receta}
receta <- recipe(tipo ~
                   org_interesada +
                   mime_type + 
                   size + 
                   name + 
                   nombre_fichero + 
                   mes_creacion +
                   dia_semana_creacion +
                   dia_creacion +
                   hora_creacion +
                   mes_modificacion +
                   dia_semana_modificacion +
                   dia_modificacion +
                   hora_modificacion,
                   data = entrenamiento)

```



Receta sin "one hot encoding". No es necesaria para modelos de árbol

```{r receta no}
receta_no <- receta %>% 
  step_upsample(tipo, over_ratio = 1) %>% 
  step_normalize(size) %>% 
  step_other(org_interesada,
             mime_type,
             threshold = 0.01,
             other = "otro") %>% 
  step_tokenize(c(name,nombre_fichero)) %>% 
  step_stopwords(c(name, nombre_fichero),language = "es") %>% 
  step_tokenfilter(c(name,nombre_fichero),max_tokens = 30) %>% 
  step_tfidf(c(name,nombre_fichero))


```

Verifica que el upsampling funciona
```{r verifica up sampling}

  prep(receta_no) %>% 
    bake(new_data = NULL) %>% 
    ggplot(aes(tipo)) +
    geom_bar()

```

Verificamos todos los elementos de la receta
```{r}
tree_prep <- prep(receta_no)
tree_prep

```

y las transformaciones a las que da lugar:

```{r}
juiced <- juice(tree_prep)
```



## Paso 4: Definir el flujo

### Con random forest
```{r flujo, eval = TRUE}
flujo <- workflow() %>% 
  add_model(rf_spec) %>% 
  add_recipe(receta_no)
```



## Paso 5: Ajustar el modelo

Esta primera es exploratoria y se seleccionan 20 puntos al azar:
```{r, eval = FALSE}
tic()
tune_res <- tune_grid(
  flujo,
  resamples = pliegos,
  grid = 20,
  verbose = TRUE
)
toc()
```

Basados en los resultados de la primera hacemos estar rejilla 
regular para buscar el espacio de mejores resultados posibles
```{r}
rf_grid <- grid_regular(
  mtry(range = c(0, 20)),
  min_n(range = c(5, 20)),
  levels = 5
)
```

Estos son los puntos a evaluar:
```{r}
rf_grid
```

Calibramos de nuevo:
```{r}
tic()
tune_res <- tune_grid(
  flujo,
  resamples = pliegos,
  grid = rf_grid
)
toc()
```

Y graficamos los resultados
```{r}
tune_res %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "AUC")
```

Esta es la grafica de los resultados que corresponde a la exploracin general
```{r, eval = FALSE}
tune_res %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "AUC")

```


Seleccionar el mejor:

```{r}
best_auc <- select_best(tune_res, "roc_auc")

final_rf <- finalize_model(
  rf_spec,
  best_auc
)

final_rf
```

```{r}
final_wf <- workflow() %>%
  add_recipe(receta_no) %>%
  add_model(final_rf)

final_res <- final_wf %>%
  last_fit(division)

final_res %>%
  collect_metrics()

```


## Paso 6: Evaluar el modelo

```{r evaluar entrenamiento, eval = TRUE}
metricas <- collect_metrics(final_res)
predicciones <- collect_predictions(final_res)
metricas

```


### Graficar curvas ROC

```{r curvas roc }
predicciones %>%
  group_by(id) %>%
  roc_curve(truth = tipo, .pred_200:.pred_600,na_rm = TRUE) %>%
  autoplot() +
  labs(
    color = NULL,
    title = "ROC para area",
    subtitle = "Cada pliego un color diferente"
  )
```



### Comparación con el conjunto de prueba




y se obtienen las metricas y predicciones respectivas:
```{r metricas prueba}
final_res_metrics <- collect_metrics(final_res)
final_res_predictions <- collect_predictions(final_res)
correlacion_matthews <- mcc(final_res_predictions,truth = tipo, estimate = .pred_class)
final_res_metrics <- bind_rows(final_res_metrics, correlacion_matthews) %>% 
  select(-.config)

final_res_metrics


```

### Importancia de variables


```{r importancia de variables}
final_res %>% 
  pluck(".workflow", 1) %>%   
  pull_workflow_fit() %>% 
  vip(geom = "point", num_features = 15)
```

### Matriz de confusión final

```{r}
final_res_predictions %>%
  conf_mat(truth = tipo, estimate = .pred_class) %>%
  autoplot(type = "heatmap")
```

### Curva ROC para el conjunto de prueba:


```{r curva ROC para conjunto de prueba}
final_res_predictions %>%
  roc_curve(truth = tipo, .pred_200:.pred_600,na_rm = TRUE) %>%
  autoplot()
```

## Paso 7: Guardar el modelo para pasos futuros

Potencialmente, se guarda el modelo como un objeto binario para ser usado por los 
meta clasificadores de la arquitectura
```{r, eval = TRUE}
mejor <- final_res %>% 
  pluck(".workflow", 1) %>%   
  pull_workflow_fit()

saveRDS(mejor, file = "modelo_metadata.rds")
write_csv(final_res_metrics,"ficha_metadatos.csv")

```


