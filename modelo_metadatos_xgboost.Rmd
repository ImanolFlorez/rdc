---
title: 'Ruta del Cacao'
subtitle: "Modelización: Metadatos con xgboost"
output: 
    html_document: 
      code_download: true 
      number_sections: yes
      code_folding: hide
      theme: lumen
      toc: yes
      toc_float:
        collapsed: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_chunk$set(cache = TRUE)
library(dplyr)
library(janitor)
library(readxl)
library(skimr)
library(gt)
library(stringr)
#library(text2vec)
#library(LDAvis)
library(tidyr)
library(ggplot2)
library(lubridate)
library(stringr)
library(tidymodels)
library(tidytext)
library(stopwords)
#library(purrr)
library(textrecipes)
library(discrim)
library(vip)
library(themis)
library(tictoc)
library(ranger)
library(xgboost)

library(doParallel)
all_cores <- parallel::detectCores(logical = FALSE)
registerDoParallel(cores = all_cores - 2)

set.seed(4321)
```
# Introducción

Aquí intentamos un modelo con los metadatos de Ruta del Cacaco y 
utilizando *xgboost* y la variable *area*. Las categorías minoritarias
"CAC"y "100" se clasificaron como "otros'


# Ingestión de los datos
A diferencia del modelo de random forest, aquí dejamos todas las variables
que tienen que ver con fechas como numéricas, que es como las prefiere xgboost
```{r lectura}
crudos <- read_excel("datos/RDC_2019_V1.xlsx") %>% 
  clean_names() 

datos <- crudos  %>% 
  select(code,
         modo,
         name, 
         datecreated, 
         datemodified,
         author,
         org_interesada_remitente,
         org_interesada_destinatario,
         nombre_fichero,
         mimetype,
         size,
         path,
         area,
         nombre_tipo_documental,
         nombre_padre,
         nombre_abuelo,
         en_expte,
         nombre_serie_documental) %>% 
  unite(org_interesada,org_interesada_remitente:org_interesada_destinatario,
        remove = TRUE,
        na.rm = TRUE) %>% 
  mutate(
    date_created = ymd_hms(datecreated,tz = "UTC") - hours(5),
    date_modified = ymd_hms(datemodified,tz = "UTC") - hours(5)
    ) %>% 
   mutate(
    mes_creacion = month(datecreated,label = FALSE,abbr = FALSE),
    dia_semana_creacion = wday(datecreated,label = FALSE, 
                               week_start = 1,abbr = FALSE),
    dia_creacion = day(datecreated),
    hora_creacion = hour(datecreated),
    mes_modificacion = month(datemodified,label = FALSE,abbr = FALSE),
    dia_semana_modificacion = wday(datemodified,label = FALSE,
                                   week_start = 1,abbr = FALSE),
    dia_modificacion = day(datemodified),
    hora_modificacion = hour(datemodified)) %>% 
  rename(mime_type = mimetype) %>% 
  na.omit()
      

```

# Limpieza

Excluimos NULL y reclasificamos bajo "otros" categorías menos frecuentes

```{r definicion de tipos}

a_excluir <- c("100","CAC")
datos <- datos %>%
  mutate(
    tipo = factor(if_else(
      area  %in% a_excluir,"otros",area))
  )
#save(datos, file =  "procesados.Rdata" )
```

Examinamos la nueva distribución de los tipos:
```{r mostrar tipos}
datos %>% 
  group_by(tipo) %>% 
  summarize(frecuencia = n()) %>%
  arrange(desc(frecuencia)) %>% 
  mutate(
    total = sum(frecuencia),
    porcentaje = (frecuencia/total)*100,
    acumulado = cumsum(porcentaje),
    posicion = 1:n()
    ) %>%  
  select(-total) %>% 
  ungroup() %>% 
  gt()

```

```{r}
n_clases <- datos %>% 
  distinct(tipo) %>% 
  tally() %>%
  pull()
```

# Construcción del modelo

## Paso 1: División

Estoy colocando solo 2 pliegos para propósitos de prueba:

```{r}
division <- initial_split(datos, strata = tipo)
entrenamiento <- training(division)
prueba <- testing(division)
pliegos <- vfold_cv(entrenamiento,v = 2,strata = tipo)
```

## Paso 2: Especificación del modelo


Colocamos manualmente todos los parámetros en vez de tratar de ajustar el modelo
automáticamente.

Los paramétros son:

- trees: el número de árboles que contiene el conjunto

- tree_depth: la profundidad máxima (número de divisiones) del árbol

- min_n: el mero mínimo requerido de puntos en un nodo para que este se subdivida 

- learn_rate: la tasa a la cual el algoritmo de boosting se adapta en cada iteración

- loss_reduction: la reducción en la función de pérdida requerida para continuar
la división

- sample_size: la cantidad o proporción de los datos usada en la rutina de ajuste

- mtry: el número de predictores (o la proporción) que van a muestrarse 
aleatoriamente en cada división cuando se crea el modelo de árbol

- stop_iter: el número de interacciones sin mejorar antes de que el algoritmo
se detenga

```{r}
xgb_spec <- boost_tree(
  trees = 2, 
  tree_depth = 5,
  min_n = 13,                      
  learn_rate = 0.02,                         
) %>% 
  set_engine("xgboost",objective = "multi:softprob",
             num_class = n_clases, verbose = 2) %>% 
  set_mode("classification")

```

Así es como lo hace Julia Silge (https://juliasilge.com/blog/xgboost-tune-volleyball/) en su ejemplo:

```{r eval= FALSE}
xgb_spec <- boost_tree(
  trees = 500, 
  tree_depth = tune(), min_n = tune(), 
  loss_reduction = tune(),                     ## first three: model complexity
  sample_size = tune(), mtry = tune(),         ## randomness
  learn_rate = tune(),                         ## step size
) %>% 
  set_engine("xgboost",objective = "multi:softprob", eval_metric = "mlogloss",
             num_class = n_clases, verbose = 2) %>% 
  set_mode("classification")
```

Excepto que en nuestro caso la clasificación es múltiple y por eso se cambia
la función objetivo. Para la métrica de evaluación, hay otra opción, pero
creo que esa es la opción por defecto actualmente


```{r eval = FALSE}
xgb_grid <- grid_latin_hypercube(
  tree_depth(),
  min_n(),
  loss_reduction(),
  sample_size = sample_prop(),
  finalize(mtry(), entrenamiento),
  learn_rate(),
  size = 15
)
```

## Paso 3: Establecer la receta
```{r receta}
receta <- recipe(tipo ~
                   org_interesada +
                   mime_type + 
                   size + 
                   name + 
                   nombre_fichero + 
                   mes_creacion +
                   dia_semana_creacion +
                   dia_creacion +
                   hora_creacion +
                   mes_modificacion +
                   dia_semana_modificacion +
                   dia_modificacion +
                   hora_modificacion,
                   data = entrenamiento)

```

xgboost espera que todas las variables sean numéricas, así que cualquier variable categórica debe convertise primero. En nuestro caso, usamos "one hot encoding". 

Aquí también cambiamos el número máximo de tokens a considerar a solo 10 para `name`
y `nombre_fichero`

```{r receta dummy, eval = TRUE}
receta_dummy <- receta %>% 
  step_upsample(tipo, over_ratio = 1) %>%
  step_other(org_interesada,
             mime_type,
             threshold = 0.01,
             other = "otro") %>% 
  step_dummy(org_interesada) %>% 
  step_dummy(mime_type) %>% 
  step_normalize(size) %>% 
  step_tokenize(c(name,nombre_fichero)) %>% 
  step_stopwords(c(name, nombre_fichero),language = "es") %>% 
  step_tokenfilter(c(name,nombre_fichero),max_tokens = 10) %>% 
  step_tfidf(c(name,nombre_fichero))
   
```


Este paso es para verificar que se realizó el upsample de tipo:
```{r}
prep(receta_dummy) %>% 
  bake(new_data = NULL) %>% 
  ggplot(aes(tipo)) +
  geom_bar()

```

y este para verificar como quedan los datos con lo que se esta alimentando
el modelo:

```{r}
asi_queda <- prep(receta_dummy) %>% bake(entrenamiento)
```



## Paso 4: Definir el flujo


```{r, eval = TRUE}
# flujo <- workflow() %>% 
#   add_model(xgb_spec) %>% 
#   add_recipe(receta_dummy)

flujo <- workflow() %>% 
  add_model(xgb_spec) %>% 
  add_formula(tipo ~ .)

```


## Paso 5: Ajustar el modelo

Este es el paso más intensivo computacionalmente. Esta primera forma es la 
forma sencilla, igual a la que usamos en random forest donde no ajustabamos
automáticamente ningún parámetro

```{r, eval = TRUE}
tic()
modelo_xgb <- fit_resamples(
  flujo,
  pliegos,
  control = control_resamples(save_pred = TRUE)
  #metrics = metric_set(accuracy, sensitivity, specificity)
)
toc()

```

Esta es la forma tal como debería ser usando `tune()`:

```{r, eval = FALSE}

tic()
set.seed(234)
xgb_res <- tune_grid(
  flujo,
  resamples = pliegos,
  grid = xgb_grid,
  control = control_grid(save_pred = TRUE, verbose = TRUE)
)
toc()
```


## Paso 6: Evaluar el modelo

```{r evaluar entrenamiento, eval = FALSE}
collect_metrics(xgb_res)
```

Si funcionara la calibración automática, aquí podríamos examinar visualmente
el impacto de los valores de los diferentes parámetros


### Seleccionar el mejor modelo

```{r, eval = FALSE}
best_auc <- select_best(xgb_res, "roc_auc")
```


### Finalizar el modelo con los parametros del mejor modelo

```{r, eval = FALSE }

final_xgb <- finalize_workflow(
  xgb_wf,
  best_auc
)
```


### Comparación con el conjunto de prueba

El modelo ajustado se mide con los datos de prueba:
```{r evaluacion prueba, eval = FALSE}
final_res <- last_fit(final_xgb, division)

```


y se obtienen las metricas y predicciones respectivas:
```{r metricas prueba}
final_res_metrics <- collect_metrics(final_res)

final_res_metrics

final_res_predictions <- collect_predictions(final_res)
correlacion_matthews <- mcc(final_res_predictions,truth = tipo, estimate = .pred_class)
final_res_metrics <- bind_rows(final_res_metrics, correlacion_matthews) %>%
  select(-.config)


```

Guardamos la ficha del modelo;

```{r}
write_csv(final_res_metrics,"ficha_metadatos_xgboost.csv")
```


### Importancia de variables

A lo Julia, pero similar a lo que hicimos antes:
```{r}
final_xgb %>%
  fit(data = entrenamiento) %>%
  pull_workflow_fit() %>%
  vip(geom = "point")
```

### Matriz de confusión final

```{r}
final_res_predictions %>%
  conf_mat(truth = tipo, estimate = .pred_class) %>%
  autoplot(type = "heatmap")
```

## Paso 7: Guardar el modelo para pasos futuros

Potencialmente, se guarda el modelo como un objeto binario para ser usado por los 
meta clasificadores de la arquitectura

En el caso sencillo:

```{r}
mejor <- flujo %>% 
  fit(data = entrenamiento)
saveRDS(mejor, file = "modelo_metadata_xgboost.rds") 

```

En el caso de calibración
```{r, eval = FALSE}

mejor <- final_xgb %>%
  fit(data = entrenamiento)

saveRDS(mejor, file = "modelo_metadata_xgboost.rds")


mejor <- flujo %>% 
  fit(data = entrenamiento)
saveRDS(mejor, file = "modelo_metadata.rds") 

```

# A manera de conclusiones

No logré que esto corriera, pero lo documenté lo mejor que pude para cuando decida
retomarlo sea un poco más claro
